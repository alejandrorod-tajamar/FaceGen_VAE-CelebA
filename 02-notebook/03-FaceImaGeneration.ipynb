{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3780b57",
   "metadata": {},
   "source": [
    "### **Práctica: Generación de Rostros con VAE usando CelebA**  \n",
    "**Objetivo**: Entrenar un Variational Autoencoder (VAE) convolucional para generar rostros nuevos a partir del dataset CelebA.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f59e87",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f9779",
   "metadata": {},
   "source": [
    "### **1. Configuración Inicial**  \n",
    "**Objetivo**: Preparar el entorno y el dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b8147",
   "metadata": {},
   "source": [
    "**Instrucciones**:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb06797c",
   "metadata": {},
   "source": [
    "1. **Descargar CelebA**:  \n",
    "   - El dataset contiene ~200k imágenes de rostros.  \n",
    "   - Utilizar `kagglehub` para descargar el dataset directamente desde Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8740d431",
   "metadata": {},
   "source": [
    "2. **Preprocesamiento**:  \n",
    "   - Redimensionar imágenes a 64x64 píxeles (si no están ya en ese tamaño).  \n",
    "   - Normalizar píxeles al rango `[0, 1]`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a526d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the dataset\n",
    "img_dir = os.path.join(path, 'img_align_celeba/img_align_celeba')\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(img_dir):\n",
    "    img_dir = os.path.join(path, 'img_align_celeba', 'img_align_celeba')\n",
    "    if not os.path.exists(img_dir):\n",
    "        print(f\"Could not find the images directory. Available files in {path}:\")\n",
    "        print(os.listdir(path))\n",
    "\n",
    "# List all image files\n",
    "image_files = [f for f in os.listdir(img_dir) if f.endswith('.jpg') or f.endswith('.png')]\n",
    "print(f\"Total number of images found: {len(image_files)}\")\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(img_path, target_size=(64, 64)):\n",
    "    # Load and resize image\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize(target_size, Image.LANCZOS)\n",
    "    \n",
    "    # Convert to numpy array and normalize to [0, 1]\n",
    "    img_array = np.array(img).astype('float32') / 255.0\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "# Create a sample of images to process (limit to 5000 images to save memory)\n",
    "sample_size = min(5000, len(image_files))\n",
    "sample_files = image_files[:sample_size]\n",
    "\n",
    "# Process the sampled images\n",
    "processed_images = []\n",
    "\n",
    "# Simple progress tracking\n",
    "start_time = time.time()\n",
    "update_interval = max(1, sample_size // 20)  # Update every 5% of progress\n",
    "print(f\"Processing {sample_size} images...\")\n",
    "\n",
    "for i, img_file in enumerate(sample_files):\n",
    "    img_path = os.path.join(img_dir, img_file)\n",
    "    processed_img = preprocess_image(img_path)\n",
    "    processed_images.append(processed_img)\n",
    "    \n",
    "    # Print progress update\n",
    "    if (i + 1) % update_interval == 0 or i == sample_size - 1:\n",
    "        progress = (i + 1) / sample_size * 100\n",
    "        elapsed = time.time() - start_time\n",
    "        remaining = elapsed / (i + 1) * (sample_size - i - 1) if i > 0 else 0\n",
    "        print(f\"Progress: {progress:.1f}% ({i+1}/{sample_size}) - Elapsed: {elapsed:.1f}s - Est. remaining: {remaining:.1f}s\")\n",
    "\n",
    "# Convert to numpy array\n",
    "processed_images = np.array(processed_images)\n",
    "print(f\"Processing completed in {time.time() - start_time:.1f} seconds\")\n",
    "print(f\"Processed images shape: {processed_images.shape}\")\n",
    "print(f\"Min value: {processed_images.min()}, Max value: {processed_images.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318302b9",
   "metadata": {},
   "source": [
    "3. **Visualizar algunas imágenes procesadas**:  \n",
    "   - Verifiquemos que las imágenes se han procesado correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4cfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grid of processed sample images\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(15):  # Display 15 sample images\n",
    "    plt.subplot(3, 5, i+1)\n",
    "    plt.imshow(processed_images[i])\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03a00bb",
   "metadata": {},
   "source": [
    "4. **Crear DataLoader**:  \n",
    "   - Usar batches de 64-128 imágenes.  \n",
    "   - *pista*: `tf.data.Dataset.from_tensor_slices` permite crear un pipeline eficiente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9732cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Split the data into training and validation sets (90% training, 10% validation)\n",
    "train_size = int(0.9 * len(processed_images))\n",
    "train_images = processed_images[:train_size]\n",
    "val_images = processed_images[train_size:]\n",
    "\n",
    "print(f\"Training images: {len(train_images)}, Validation images: {len(val_images)}\")\n",
    "\n",
    "# Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(val_images)\n",
    "\n",
    "# Configure the datasets for performance\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Verify the dataset shapes\n",
    "for x_batch in train_dataset.take(1):\n",
    "    print(f\"Input batch shape: {x_batch.shape}\")\n",
    "    # Verify that the data is normalized properly\n",
    "    print(f\"Data range: [{tf.reduce_min(x_batch).numpy()}, {tf.reduce_max(x_batch).numpy()}]\")\n",
    "\n",
    "print(f\"Training batches: {tf.data.experimental.cardinality(train_dataset).numpy()}\")\n",
    "print(f\"Validation batches: {tf.data.experimental.cardinality(val_dataset).numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b64b43",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8d9670",
   "metadata": {},
   "source": [
    "### **2. Diseño del VAE Convolucional**  \n",
    "**Objetivo**: Construir un VAE con encoder y decoder convolucionales.  \n",
    "\n",
    "#### **Encoder**:  \n",
    "- **Capas**:  \n",
    "  - 4 capas convolucionales (`Conv2D`) con activación `LeakyReLU` o `ReLU`.  \n",
    "  - Reducir dimensiones espaciales progresivamente (ej: 64x64 → 32x32 → 16x16).  \n",
    "- **Capa Latente**:  \n",
    "  - Dos salidas: `z_mean` y `z_log_var` (media y log-varianza de la distribución latente).  \n",
    "  - Dimensión del espacio latente: 256.  \n",
    "- *pista*: Usar `Flatten` antes de las capas densas para `z_mean` y `z_log_var`.  \n",
    "\n",
    "#### **Reparameterization Trick**:  \n",
    "- Muestrear `z` usando:  \n",
    "  ```  \n",
    "  z = z_mean + exp(z_log_var * 0.5) * epsilon  \n",
    "  ```  \n",
    "  donde `epsilon ~ N(0, 1)`.  \n",
    "\n",
    "#### **Decoder**:  \n",
    "- **Capas**:  \n",
    "  - 4 capas `Conv2DTranspose` o `UpSampling2D + Conv2D` para aumentar resolución.  \n",
    "  - Usar activación `sigmoid` en la última capa si las imágenes están en `[0, 1]`.  \n",
    "- *pista*: Asegurar que la salida final tenga las mismas dimensiones que la entrada (64x64x3).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6534f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Set hyperparameters\n",
    "latent_dim = 256  # Size of latent space\n",
    "input_shape = (64, 64, 3)  # Shape of input images\n",
    "dropout_rate = 0.2  # Dropout rate for regularization\n",
    "\n",
    "# Create the encoder\n",
    "def build_encoder(input_shape, latent_dim, dropout_rate=0.2):\n",
    "    encoder_inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Convolutional layers with LeakyReLU activation and dropout for regularization\n",
    "    x = layers.Conv2D(32, 4, strides=2, padding='same')(encoder_inputs)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    # 32x32x32\n",
    "    \n",
    "    x = layers.Conv2D(64, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    # 16x16x64\n",
    "    \n",
    "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    # 8x8x128\n",
    "    \n",
    "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    # 4x4x256\n",
    "    \n",
    "    # Flatten the features\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    # Output layers for mean and log variance\n",
    "    z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
    "    \n",
    "    # Create the encoder model\n",
    "    encoder = Model(encoder_inputs, [z_mean, z_log_var], name='encoder')\n",
    "    return encoder\n",
    "\n",
    "# Reparameterization trick as a Keras layer\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch_size, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Create the decoder\n",
    "def build_decoder(latent_dim, output_shape, dropout_rate=0.2):\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    \n",
    "    # Calculate dimensions for reshaping\n",
    "    # For input images of 64x64, after 4 layers of Conv2D with stride 2, we get 4x4\n",
    "    units = 4 * 4 * 256  # Width * Height * Channels\n",
    "    \n",
    "    # Dense layer and reshape\n",
    "    x = layers.Dense(units)(latent_inputs)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    x = layers.Reshape((4, 4, 256))(x)\n",
    "    # 4x4x256\n",
    "    \n",
    "    # Transposed convolution layers to increase resolution\n",
    "    x = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    # 8x8x128\n",
    "    \n",
    "    x = layers.Conv2DTranspose(64, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    # 16x16x64\n",
    "    \n",
    "    x = layers.Conv2DTranspose(32, 4, strides=2, padding='same')(x)\n",
    "    x = layers.LeakyReLU(0.2)(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    # 32x32x32\n",
    "    \n",
    "    # Final layer with sigmoid activation for output in range [0, 1]\n",
    "    # No dropout in the final output layer\n",
    "    decoder_outputs = layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='sigmoid')(x)\n",
    "    # 64x64x3\n",
    "    \n",
    "    # Create the decoder model\n",
    "    decoder = Model(latent_inputs, decoder_outputs, name='decoder')\n",
    "    return decoder\n",
    "\n",
    "# Build the encoder and decoder with dropout regularization\n",
    "encoder = build_encoder(input_shape, latent_dim, dropout_rate)\n",
    "encoder.summary()\n",
    "\n",
    "# Build the decoder with dropout regularization\n",
    "decoder = build_decoder(latent_dim, input_shape, dropout_rate)\n",
    "decoder.summary()\n",
    "\n",
    "# Define the VAE model\n",
    "class VAE(Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super(VAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampling = Sampling()\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name='total_loss')\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name='reconstruction_loss')\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name='kl_loss')\n",
    "        # Add validation metrics\n",
    "        self.val_total_loss_tracker = tf.keras.metrics.Mean(name='val_loss')\n",
    "        self.val_reconstruction_loss_tracker = tf.keras.metrics.Mean(name='val_reconstruction_loss')\n",
    "        self.val_kl_loss_tracker = tf.keras.metrics.Mean(name='val_kl_loss')\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.val_total_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "            self.val_kl_loss_tracker\n",
    "        ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get encoder outputs\n",
    "            z_mean, z_log_var = self.encoder(data)\n",
    "            # Sample from the latent distribution\n",
    "            z = self.sampling([z_mean, z_log_var])\n",
    "            # Decode the sampled vector\n",
    "            reconstructed = self.decoder(z)\n",
    "            \n",
    "            # Calculate reconstruction loss (pixel-wise binary crossentropy)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstructed),\n",
    "                    axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Calculate KL divergence loss\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "            )\n",
    "            \n",
    "            # Total loss is the sum of reconstruction loss and KL loss\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        # Get gradients and apply them\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # Return metrics dictionary\n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'reconstruction_loss': self.reconstruction_loss_tracker.result(),\n",
    "            'kl_loss': self.kl_loss_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        # Get encoder outputs\n",
    "        z_mean, z_log_var = self.encoder(data)\n",
    "        # Sample from the latent distribution\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        # Decode the sampled vector\n",
    "        reconstructed = self.decoder(z)\n",
    "        \n",
    "        # Calculate reconstruction loss (pixel-wise binary crossentropy)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                tf.keras.losses.binary_crossentropy(data, reconstructed),\n",
    "                axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Calculate KL divergence loss\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "        )\n",
    "        \n",
    "        # Total loss is the sum of reconstruction loss and KL loss\n",
    "        total_loss = reconstruction_loss + kl_loss\n",
    "        \n",
    "        # Update validation metrics\n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.val_kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # Return metrics dictionary\n",
    "        return {\n",
    "            'loss': self.val_total_loss_tracker.result(),\n",
    "            'reconstruction_loss': self.val_reconstruction_loss_tracker.result(),\n",
    "            'kl_loss': self.val_kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "# Create the VAE model\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "# Compile the model\n",
    "# Need to provide a dummy loss even though we implement our own in train_step\n",
    "vae.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    # Adding a dummy loss function to prevent the ValueError\n",
    "    loss=None  # Set to None since we have custom train_step and test_step methods\n",
    ")\n",
    "\n",
    "# Display the model architecture summary\n",
    "print(\"VAE Architecture with Dropout Created Successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244a0bc2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31df73a",
   "metadata": {},
   "source": [
    "### **3. Función de Pérdida**  \n",
    "**Objetivo**: Definir la pérdida del VAE (reconstrucción + divergencia KL).  \n",
    "1. **Reconstrucción**:  \n",
    "   - Error cuadrático medio (MSE) entre imágenes originales y reconstruidas.  \n",
    "   - *Alternativa*: Pérdida de entropía cruzada binaria (BCE) si se usa `sigmoid`.  \n",
    "2. **Divergencia KL**:  \n",
    "   - Calculada entre la distribución latente y una normal estándar:  \n",
    "     ```  \n",
    "     KL = -0.5 * sum(1 + z_log_var - z_mean^2 - exp(z_log_var))  \n",
    "     ```  \n",
    "3. **Pérdida Total**: `loss = reconstruction_loss + beta * KL_loss` (beta=1 por defecto).  \n",
    "   - *pista*: Usar `beta` como hiperparámetro para ajustar el trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fc0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: We've already implemented the loss functions inside our VAE class in the previous step\n",
    "# Let's experiment with different beta values for the KL divergence term\n",
    "\n",
    "# Define a custom VAE with beta parameter\n",
    "class BetaVAE(Model):\n",
    "    def __init__(self, encoder, decoder, beta=1.0, **kwargs):\n",
    "        super(BetaVAE, self).__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.sampling = Sampling()\n",
    "        self.beta = beta\n",
    "        self.total_loss_tracker = tf.keras.metrics.Mean(name='total_loss')\n",
    "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(name='reconstruction_loss')\n",
    "        self.kl_loss_tracker = tf.keras.metrics.Mean(name='kl_loss')\n",
    "        # Add validation metrics\n",
    "        self.val_total_loss_tracker = tf.keras.metrics.Mean(name='val_loss')\n",
    "        self.val_reconstruction_loss_tracker = tf.keras.metrics.Mean(name='val_reconstruction_loss')\n",
    "        self.val_kl_loss_tracker = tf.keras.metrics.Mean(name='val_kl_loss')\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "            self.val_total_loss_tracker,\n",
    "            self.val_reconstruction_loss_tracker,\n",
    "            self.val_kl_loss_tracker\n",
    "        ]\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = self.encoder(inputs)\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        reconstructed = self.decoder(z)\n",
    "        return reconstructed\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get encoder outputs\n",
    "            z_mean, z_log_var = self.encoder(data)\n",
    "            # Sample from the latent distribution\n",
    "            z = self.sampling([z_mean, z_log_var])\n",
    "            # Decode the sampled vector\n",
    "            reconstructed = self.decoder(z)\n",
    "            \n",
    "            # Calculate reconstruction loss\n",
    "            # Option 1: Mean Squared Error (MSE)\n",
    "            # reconstruction_loss = tf.reduce_mean(\n",
    "            #     tf.reduce_sum(\n",
    "            #         tf.square(data - reconstructed), \n",
    "            #         axis=(1, 2)\n",
    "            #     )\n",
    "            # )\n",
    "            \n",
    "            # Option 2: Binary Cross-Entropy (BCE) - better for image pixels in [0,1]\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    tf.keras.losses.binary_crossentropy(data, reconstructed),\n",
    "                    axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Calculate KL divergence loss\n",
    "            # KL divergence between the latent distribution and a standard normal\n",
    "            kl_loss = -0.5 * tf.reduce_mean(\n",
    "                tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "            )\n",
    "            \n",
    "            # Total loss with beta parameter to control the trade-off\n",
    "            total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        \n",
    "        # Get gradients and apply them\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        \n",
    "        # Update metrics\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # Return metrics dictionary\n",
    "        return {\n",
    "            'loss': self.total_loss_tracker.result(),\n",
    "            'reconstruction_loss': self.reconstruction_loss_tracker.result(),\n",
    "            'kl_loss': self.kl_loss_tracker.result()\n",
    "        }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        # Get encoder outputs\n",
    "        z_mean, z_log_var = self.encoder(data)\n",
    "        # Sample from the latent distribution\n",
    "        z = self.sampling([z_mean, z_log_var])\n",
    "        # Decode the sampled vector\n",
    "        reconstructed = self.decoder(z)\n",
    "        \n",
    "        # Calculate reconstruction loss (pixel-wise binary crossentropy)\n",
    "        reconstruction_loss = tf.reduce_mean(\n",
    "            tf.reduce_sum(\n",
    "                tf.keras.losses.binary_crossentropy(data, reconstructed),\n",
    "                axis=(1, 2)\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Calculate KL divergence loss\n",
    "        kl_loss = -0.5 * tf.reduce_mean(\n",
    "            tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1)\n",
    "        )\n",
    "        \n",
    "        # Total loss with beta parameter\n",
    "        total_loss = reconstruction_loss + self.beta * kl_loss\n",
    "        \n",
    "        # Update validation metrics\n",
    "        self.val_total_loss_tracker.update_state(total_loss)\n",
    "        self.val_reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.val_kl_loss_tracker.update_state(kl_loss)\n",
    "        \n",
    "        # Return metrics dictionary\n",
    "        return {\n",
    "            'loss': self.val_total_loss_tracker.result(),\n",
    "            'reconstruction_loss': self.val_reconstruction_loss_tracker.result(),\n",
    "            'kl_loss': self.val_kl_loss_tracker.result()\n",
    "        }\n",
    "\n",
    "# Create models with different beta values to experiment with\n",
    "# Higher beta enforces more regularization to the latent space\n",
    "# Lower beta allows more focus on reconstruction quality\n",
    "beta_values = [0.5, 1.0, 2.0]\n",
    "beta_vae_models = {}\n",
    "\n",
    "for beta in beta_values:\n",
    "    beta_vae = BetaVAE(encoder, decoder, beta=beta)\n",
    "    beta_vae.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=None  # Set to None since we have custom methods\n",
    "    )\n",
    "    beta_vae_models[f\"beta_{beta}\"] = beta_vae\n",
    "\n",
    "print(\"Created VAE models with different beta values:\")\n",
    "for beta_name, model in beta_vae_models.items():\n",
    "    print(f\"- {beta_name}\")\n",
    "\n",
    "# Visualization of the loss function components\n",
    "def plot_loss_components():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create sample data for visualization\n",
    "    z_mean_range = np.linspace(-3, 3, 100)\n",
    "    z_log_var_range = np.linspace(-3, 3, 100)\n",
    "    \n",
    "    kl_losses = []\n",
    "    for z_mean in z_mean_range:\n",
    "        for z_log_var in z_log_var_range:\n",
    "            # KL divergence term for a single latent dimension\n",
    "            kl = -0.5 * (1 + z_log_var - z_mean**2 - np.exp(z_log_var))\n",
    "            kl_losses.append((z_mean, z_log_var, kl))\n",
    "    \n",
    "    # Plot KL divergence as a function of z_mean and z_log_var\n",
    "    z_means = [x[0] for x in kl_losses]\n",
    "    z_log_vars = [x[1] for x in kl_losses]\n",
    "    kl_values = [x[2] for x in kl_losses]\n",
    "    \n",
    "    plt.scatter(z_means, z_log_vars, c=kl_values, cmap='viridis', alpha=0.7)\n",
    "    plt.colorbar(label='KL Divergence')\n",
    "    plt.xlabel('z_mean')\n",
    "    plt.ylabel('z_log_var')\n",
    "    plt.title('KL Divergence as a function of z_mean and z_log_var')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Illustrate the effect of beta on total loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Example fixed values\n",
    "    recon_loss = 1.0\n",
    "    kl_loss_values = np.linspace(0, 2, 100)\n",
    "    \n",
    "    for beta in beta_values:\n",
    "        total_loss = recon_loss + beta * kl_loss_values\n",
    "        plt.plot(kl_loss_values, total_loss, label=f'β = {beta}')\n",
    "    \n",
    "    plt.xlabel('KL Loss')\n",
    "    plt.ylabel('Total Loss (with fixed reconstruction loss)')\n",
    "    plt.title('Effect of β on Total Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Run the visualization\n",
    "plot_loss_components()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7880dafc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecb8fa8",
   "metadata": {},
   "source": [
    "### **4. Entrenamiento**  \n",
    "**Objetivo**: Entrenar el modelo y monitorear la generación.  \n",
    "**Instrucciones**:  \n",
    "1. **Compilar el modelo**:  \n",
    "   - Optimizador: `Adam` con learning rate=0.0005.  \n",
    "   - Métricas opcionales: Seguir `loss`, `reconstruction_loss`, `KL_loss` por separado.  \n",
    "2. **Callbacks útiles**:  \n",
    "   - `ModelCheckpoint`: Guardar el mejor modelo.  \n",
    "   - `TensorBoard`: Visualizar curvas de pérdida.  \n",
    "   - `EarlyStopping`: Detener el entrenamiento si la pérdida de validación no mejora.  \n",
    "   - `ReduceLROnPlateau`: Reducir la tasa de aprendizaje si la pérdida se estanca.  \n",
    "3. **Entrenar**:  \n",
    "   - Épocas: 30-50 (CelebA requiere más tiempo que CIFAR-10).  \n",
    "   - Batch size: 64-128 (depende de la memoria de GPU).  \n",
    "4. **Monitoreo visual**:  \n",
    "   - Generar rostros nuevos cada 5 épocas muestreando `z ~ N(0, 1)`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8a4449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, LambdaCallback, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create directories for saving model checkpoints and generated images\n",
    "model_dir = os.path.join('model', 'vae_checkpoints')\n",
    "generated_dir = os.path.join('model', 'generated_faces')\n",
    "logs_dir = os.path.join('model', 'logs', 'vae_training')\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(generated_dir, exist_ok=True)\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "\n",
    "# Create a fixed latent sample for consistent generation during training\n",
    "fixed_z_sample = tf.random.normal(shape=(15, latent_dim))\n",
    "\n",
    "# Function to generate and save images during training\n",
    "def generate_and_save_images(epoch, z_sample=None, n_samples=15, rows=3, cols=5):\n",
    "    if z_sample is None:\n",
    "        # Use the fixed sample for consistency\n",
    "        z_sample = fixed_z_sample\n",
    "        \n",
    "    # Generate images from the decoder\n",
    "    generated_images = decoder(z_sample)\n",
    "    \n",
    "    # Plot the generated images\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n_samples):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        plt.imshow(generated_images[i])\n",
    "        plt.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'Generated Faces - Epoch {epoch}')\n",
    "    \n",
    "    # Save the plot\n",
    "    save_path = os.path.join(generated_dir, f'generated_faces_epoch_{epoch}.png')\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Custom callback class for generating images\n",
    "class GenerateImagesCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, z_sample, interval=5):\n",
    "        super(GenerateImagesCallback, self).__init__()\n",
    "        self.z_sample = z_sample\n",
    "        self.interval = interval\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.interval == 0 or epoch == 0:\n",
    "            generate_and_save_images(epoch + 1, self.z_sample)\n",
    "\n",
    "# 1. TensorBoard callback for visualizing training progress\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=logs_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    update_freq='epoch'  # Only update per epoch to avoid None values\n",
    ")\n",
    "\n",
    "# 2. ModelCheckpoint to save the best model during training\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(model_dir, 'vae_epoch_{epoch:03d}_loss_{loss:.4f}.weights.h5'),\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 3. Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,  # Number of epochs with no improvement after which training will stop\n",
    "    restore_best_weights=True,  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 4. Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,  # Factor by which the learning rate will be reduced\n",
    "    patience=5,  # Number of epochs with no improvement after which learning rate will be reduced\n",
    "    min_lr=1e-6,  # Lower bound on the learning rate\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 5. Generate images callback\n",
    "generate_images_callback = GenerateImagesCallback(fixed_z_sample, interval=5)\n",
    "\n",
    "# Build the model by passing a sample batch through it\n",
    "print(\"Building the VAE model...\")\n",
    "# Get a sample batch from the dataset\n",
    "for x_batch in train_dataset.take(1):\n",
    "    # Run a forward pass to build the model\n",
    "    _ = vae(x_batch)\n",
    "    print(f\"Model successfully built with input shape: {x_batch.shape}\")\n",
    "\n",
    "# Generate initial images before training\n",
    "print(\"Generating images before training...\")\n",
    "initial_images_path = generate_and_save_images(0, fixed_z_sample)\n",
    "print(f\"Initial images saved to: {initial_images_path}\")\n",
    "\n",
    "# Train the model with callbacks - increase epochs but with early stopping to prevent overfitting\n",
    "history = vae.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,  # Increased from 50 to 100, early stopping will prevent overfitting\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[\n",
    "        checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        generate_images_callback,\n",
    "        early_stopping,\n",
    "        reduce_lr\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Print training summary\n",
    "print(f\"Training completed for {len(history.history['loss'])} epochs\")\n",
    "print(f\"Best validation loss: {min(history.history['val_loss'])}\")\n",
    "\n",
    "# Save the final model weights\n",
    "final_model_path = os.path.join(model_dir, 'vae_final_model.weights.h5')\n",
    "vae.save_weights(final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")\n",
    "\n",
    "# Explore the latent space by interpolating between two random points\n",
    "n_interpolations = 10  # Number of interpolation steps\n",
    "z_start = tf.random.normal(shape=(1, latent_dim))  # Random point in latent space\n",
    "z_end = tf.random.normal(shape=(1, latent_dim))  # Another random point\n",
    "\n",
    "# Linear interpolation in latent space\n",
    "z_interpolated = tf.concat([\n",
    "    z_start + (z_end - z_start) * t / n_interpolations\n",
    "    for t in range(n_interpolations + 1)\n",
    "], axis=0)\n",
    "\n",
    "# Generate and save interpolated images\n",
    "interpolation_path = generate_and_save_images(\n",
    "    epoch='interp',\n",
    "    z_sample=z_interpolated,\n",
    "    n_samples=n_interpolations + 1,\n",
    "    rows=2,\n",
    "    cols=6\n",
    ")\n",
    "print(f\"Interpolation images saved to: {interpolation_path}\")\n",
    "\n",
    "# Visualize the training history (making sure we handle the case if validation metrics are missing)\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot training metrics\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Total Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['reconstruction_loss'], label='Train')\n",
    "if 'val_reconstruction_loss' in history.history:\n",
    "    plt.plot(history.history['val_reconstruction_loss'], label='Validation')\n",
    "plt.title('Reconstruction Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['kl_loss'], label='Train')\n",
    "if 'val_kl_loss' in history.history:\n",
    "    plt.plot(history.history['val_kl_loss'], label='Validation')\n",
    "plt.title('KL Divergence Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1d6a4c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192fe261",
   "metadata": {},
   "source": [
    "### **5. Generación y Evaluación**  \n",
    "**Objetivo**: Crear rostros nuevos y evaluar la calidad.  \n",
    "**Instrucciones**:  \n",
    "1. **Generación**:  \n",
    "   - Muestrear vectores `z` de `N(0, I)` y pasarlos por el decoder.  \n",
    "   - *pista*: Si el espacio latente es 2D, se puede visualizar una cuadrícula de rostros variando `z`.  \n",
    "2. **Evaluación cualitativa**:  \n",
    "   - ¿Los rostros generados son diversos y realistas?  \n",
    "   - ¿Existe \"mode collapse\" (todas las generaciones son similares)?  \n",
    "3. **Evaluación cuantitativa (opcional)**:  \n",
    "   - Métricas como **FID** (Fréchet Inception Distance) comparan distribuciones de imágenes reales y generadas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f25f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvWSL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
